{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNxS0pJ7GG+AXkeGjLdOlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArynAgarwal/NLP-/blob/main/NLP_on_scrapped_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eEmJT3r_qRX",
        "outputId": "8ee1abae-fa84-4f29-eda4-463a7700fd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4 requests openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Load input data from Excel file\n",
        "input_file = '/content/Input.xlsx'\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Function to extract article text from a given URL\n",
        "def extract_article_text(url):\n",
        "    try:\n",
        "        # Send a GET request to the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for bad requests\n",
        "\n",
        "        # Parse the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract article title and text\n",
        "        title = soup.title.text.strip()\n",
        "        article_text = ' '.join([p.text.strip() for p in soup.find_all('p')])\n",
        "\n",
        "        return title, article_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting data from {url}: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "# Loop through each row in the DataFrame and extract data\n",
        "for index, row in df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    title, article_text = extract_article_text(url)\n",
        "\n",
        "    if title and article_text:\n",
        "        # Save the extracted data to a text file\n",
        "        output_file = f\"{url_id}.txt\"\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            file.write(f\"{title}\\n\\n{article_text}\")\n",
        "\n",
        "        print(f\"Data extracted from {url} and saved to {output_file}\")\n",
        "output_file = f\"/content/{url_id}.txt\"\n",
        "print(\"Extraction process completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uctvxQ1z_22n",
        "outputId": "794457b6-03df-4278-d6d6-23e98b048bc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data extracted from https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/ and saved to blackassign0001.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/ and saved to blackassign0002.txt\n",
            "Data extracted from https://insights.blackcoffer.com/internet-demands-evolution-communication-impact-and-2035s-alternative-pathways/ and saved to blackassign0003.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-in-upcoming-future/ and saved to blackassign0004.txt\n",
            "Data extracted from https://insights.blackcoffer.com/ott-platform-and-its-impact-on-the-entertainment-industry-in-future/ and saved to blackassign0005.txt\n",
            "Data extracted from https://insights.blackcoffer.com/the-rise-of-the-ott-platform-and-its-impact-on-the-entertainment-industry-by-2040/ and saved to blackassign0006.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-cyber-crime-and-its-effects/ and saved to blackassign0007.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035-2/ and saved to blackassign0008.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040-2/ and saved to blackassign0009.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040/ and saved to blackassign0010.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035/ and saved to blackassign0011.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/ and saved to blackassign0012.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-e-health-and-its-impact-on-humans-by-the-year-2030/ and saved to blackassign0013.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/ and saved to blackassign0014.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2/ and saved to blackassign0015.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2-2/ and saved to blackassign0016.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/ and saved to blackassign0017.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030/ and saved to blackassign0018.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-does-marketing-influence-businesses-and-consumers/ and saved to blackassign0019.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-advertisement-increase-your-market-value/ and saved to blackassign0020.txt\n",
            "Data extracted from https://insights.blackcoffer.com/negative-effects-of-marketing-on-society/ and saved to blackassign0021.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-advertisement-marketing-affects-business/ and saved to blackassign0022.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rising-it-cities-will-impact-the-economy-environment-infrastructure-and-city-life-by-the-year-2035/ and saved to blackassign0023.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-ott-platform-and-its-impact-on-entertainment-industry-by-the-year-2030/ and saved to blackassign0024.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-electric-vehicles-and-its-impact-on-livelihood-by-2040/ and saved to blackassign0025.txt\n",
            "Data extracted from https://insights.blackcoffer.com/rise-of-electric-vehicle-and-its-impact-on-livelihood-by-the-year-2040/ and saved to blackassign0026.txt\n",
            "Data extracted from https://insights.blackcoffer.com/oil-prices-by-the-year-2040-and-how-it-will-impact-the-world-economy/ and saved to blackassign0027.txt\n",
            "Data extracted from https://insights.blackcoffer.com/an-outlook-of-healthcare-by-the-year-2040-and-how-it-will-impact-human-lives/ and saved to blackassign0028.txt\n",
            "Data extracted from https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/ and saved to blackassign0029.txt\n",
            "Data extracted from https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/ and saved to blackassign0030.txt\n",
            "Data extracted from https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/ and saved to blackassign0031.txt\n",
            "Data extracted from https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/ and saved to blackassign0032.txt\n",
            "Data extracted from https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/ and saved to blackassign0033.txt\n",
            "Data extracted from https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/ and saved to blackassign0034.txt\n",
            "Data extracted from https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/ and saved to blackassign0035.txt\n",
            "Error extracting data from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Data extracted from https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/ and saved to blackassign0037.txt\n",
            "Data extracted from https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/ and saved to blackassign0038.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/ and saved to blackassign0039.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/ and saved to blackassign0040.txt\n",
            "Data extracted from https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/ and saved to blackassign0041.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/ and saved to blackassign0042.txt\n",
            "Data extracted from https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/ and saved to blackassign0043.txt\n",
            "Data extracted from https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/ and saved to blackassign0044.txt\n",
            "Data extracted from https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/ and saved to blackassign0045.txt\n",
            "Data extracted from https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/ and saved to blackassign0046.txt\n",
            "Data extracted from https://insights.blackcoffer.com/evolution-of-advertising-industry/ and saved to blackassign0047.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/ and saved to blackassign0048.txt\n",
            "Error extracting data from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Data extracted from https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/ and saved to blackassign0050.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/ and saved to blackassign0051.txt\n",
            "Data extracted from https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/ and saved to blackassign0052.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/ and saved to blackassign0053.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/ and saved to blackassign0054.txt\n",
            "Data extracted from https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/ and saved to blackassign0055.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/ and saved to blackassign0056.txt\n",
            "Data extracted from https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/ and saved to blackassign0057.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-we-forecast-future-technologies/ and saved to blackassign0058.txt\n",
            "Data extracted from https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/ and saved to blackassign0059.txt\n",
            "Data extracted from https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/ and saved to blackassign0060.txt\n",
            "Data extracted from https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/ and saved to blackassign0061.txt\n",
            "Data extracted from https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/ and saved to blackassign0062.txt\n",
            "Data extracted from https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/ and saved to blackassign0063.txt\n",
            "Data extracted from https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/ and saved to blackassign0064.txt\n",
            "Data extracted from https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/ and saved to blackassign0065.txt\n",
            "Data extracted from https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/ and saved to blackassign0066.txt\n",
            "Data extracted from https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/ and saved to blackassign0067.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/ and saved to blackassign0068.txt\n",
            "Data extracted from https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/ and saved to blackassign0069.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/ and saved to blackassign0070.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/ and saved to blackassign0071.txt\n",
            "Data extracted from https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/ and saved to blackassign0072.txt\n",
            "Data extracted from https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/ and saved to blackassign0073.txt\n",
            "Data extracted from https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/ and saved to blackassign0074.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/ and saved to blackassign0075.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/ and saved to blackassign0076.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/ and saved to blackassign0077.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/ and saved to blackassign0078.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/ and saved to blackassign0079.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/ and saved to blackassign0080.txt\n",
            "Data extracted from https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/ and saved to blackassign0081.txt\n",
            "Data extracted from https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/ and saved to blackassign0082.txt\n",
            "Data extracted from https://insights.blackcoffer.com/human-rights-outlook/ and saved to blackassign0083.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/ and saved to blackassign0084.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/ and saved to blackassign0085.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/ and saved to blackassign0086.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/ and saved to blackassign0087.txt\n",
            "Data extracted from https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/ and saved to blackassign0088.txt\n",
            "Data extracted from https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/ and saved to blackassign0089.txt\n",
            "Data extracted from https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/ and saved to blackassign0090.txt\n",
            "Data extracted from https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/ and saved to blackassign0091.txt\n",
            "Data extracted from https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/ and saved to blackassign0092.txt\n",
            "Data extracted from https://insights.blackcoffer.com/travel-and-tourism-outlook/ and saved to blackassign0093.txt\n",
            "Data extracted from https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/ and saved to blackassign0094.txt\n",
            "Data extracted from https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/ and saved to blackassign0095.txt\n",
            "Data extracted from https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/ and saved to blackassign0096.txt\n",
            "Data extracted from https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/ and saved to blackassign0097.txt\n",
            "Data extracted from https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/ and saved to blackassign0098.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/ and saved to blackassign0099.txt\n",
            "Data extracted from https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/ and saved to blackassign0100.txt\n",
            "Extraction process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Specify the file names\n",
        "file_names = [f\"blackassign{i:04d}.txt\" for i in range(1, 101)]\n",
        "\n",
        "# Zip the files into a single archive\n",
        "zip_file_path = \"/content/output_files.zip\"\n",
        "with ZipFile(zip_file_path, 'w') as zip_file:\n",
        "    for file_name in file_names:\n",
        "        try:\n",
        "            zip_file.write(file_name)\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"Skipping {file_name} - File not found.\")\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "KhcahL1JCDt9",
        "outputId": "32fe60ee-4eea-4926-fb1c-c62f763b6312"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping blackassign0036.txt - File not found.\n",
            "Skipping blackassign0049.txt - File not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_70dd0ac1-0bdc-4a6e-9eef-02aaaa701f28\", \"output_files.zip\", 812229)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the extracted text and perform textual analysis\n",
        "def perform_textual_analysis(article_text):\n",
        "    # Tokenize the words and sentences\n",
        "    words = word_tokenize(article_text)\n",
        "    sentences = sent_tokenize(article_text)\n",
        "\n",
        "    # Remove stopwords and punctuations\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Counting variables\n",
        "    positive_score = 0\n",
        "    negative_score = 0\n",
        "    complex_word_count = 0\n",
        "    total_syllables = 0\n",
        "    personal_pronouns = 0\n",
        "\n",
        "    # Positive and Negative Dictionaries (You may need to customize these dictionaries)\n",
        "    positive_words = [\"positive\", \"good\", \"happy\", ...]\n",
        "    negative_words = [\"negative\", \"bad\", \"unhappy\", ...]\n",
        "\n",
        "    for word in words:\n",
        "        # Positive Score\n",
        "        if word in positive_words:\n",
        "            positive_score += 1\n",
        "\n",
        "        # Negative Score\n",
        "        elif word in negative_words:\n",
        "            negative_score += 1\n",
        "\n",
        "        # Syllable Count\n",
        "        total_syllables += sum([1 for char in word if char in 'aeiouAEIOU'])\n",
        "\n",
        "        # Personal Pronouns\n",
        "        if word.lower() in [\"i\", \"we\", \"my\", \"ours\", \"us\"]:\n",
        "            personal_pronouns += 1\n",
        "\n",
        "        # Complex Words\n",
        "        if len(re.findall('[aeiouAEIOU]{3,}', word)) > 1:\n",
        "            complex_word_count += 1\n",
        "\n",
        "    # Calculate other variables\n",
        "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
        "    subjectivity_score = (positive_score + negative_score) / (len(words) + 0.000001)\n",
        "    avg_sentence_length = len(words) / len(sentences)\n",
        "    percentage_complex_words = complex_word_count / len(words)\n",
        "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "    avg_words_per_sentence = len(words) / len(sentences)\n",
        "    word_count = len(words)\n",
        "    syllables_per_word = total_syllables / len(words)\n",
        "    avg_word_length = sum(len(word) for word in words) / len(words)\n",
        "\n",
        "    # Return the results\n",
        "    return {\n",
        "        'Positive Score': positive_score,\n",
        "        'Negative Score': negative_score,\n",
        "        'Polarity Score': polarity_score,\n",
        "        'Subjectivity Score': subjectivity_score,\n",
        "        'Average Sentence Length': avg_sentence_length,\n",
        "        'Percentage of Complex Words': percentage_complex_words,\n",
        "        'Fog Index': fog_index,\n",
        "        'Average Number of Words Per Sentence': avg_words_per_sentence,\n",
        "        'Complex Word Count': complex_word_count,\n",
        "        'Word Count': word_count,\n",
        "        'Syllable Per Word': syllables_per_word,\n",
        "        'Personal Pronouns': personal_pronouns,\n",
        "        'Average Word Length': avg_word_length,\n",
        "    }\n",
        "\n",
        "# Read the input data (URL_ID and URL)\n",
        "input_data = pd.read_excel('/content/input.xlsx')\n",
        "\n",
        "# Initialize an empty DataFrame for the output\n",
        "output_data = pd.DataFrame(columns=['URL_ID', 'URL'] + list(perform_textual_analysis('')))\n",
        "\n",
        "# Loop through each row in the input data\n",
        "for index, row in input_data.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    # Read the article text from the corresponding file\n",
        "    file_path = f\"{url_id}.txt\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        article_text = file.read()\n",
        "\n",
        "    # Perform textual analysis\n",
        "    analysis_results = perform_textual_analysis(article_text)\n",
        "\n",
        "    # Append the results to the output DataFrame\n",
        "    output_data = output_data.append({'URL_ID': url_id, 'URL': url, **analysis_results}, ignore_index=True)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "output_data.to_excel('output_results.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "KwRJi_XpCDn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKSoqwC3TXjm",
        "outputId": "8616b7ac-3579-4b44-ad0c-c97575955021"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Download necessary resources for NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the input data from the extracted text files\n",
        "input_folder = \"/content/drive/MyDrive/NLP/extracted_files\"\n",
        "output_structure_file = \"/content/drive/MyDrive/NLP/Output Data Structure.xlsx\"\n",
        "\n",
        "# Read the output structure file\n",
        "output_structure_df = pd.read_excel(output_structure_file)\n",
        "\n",
        "# Create lists to store calculated values\n",
        "positive_scores = []\n",
        "negative_scores = []\n",
        "polarity_scores = []\n",
        "subjectivity_scores = []\n",
        "avg_sentence_lengths = []\n",
        "percentage_complex_words = []\n",
        "fog_indices = []\n",
        "avg_words_per_sentence = []\n",
        "complex_word_counts = []\n",
        "word_counts = []\n",
        "syllable_per_words = []\n",
        "personal_pronouns = []\n",
        "avg_word_lengths = []\n",
        "\n",
        "# Load stop words\n",
        "# Load stop words from \"StopWords_Auditor.txt\" only\n",
        "stop_words_file_path = \"/content/drive/MyDrive/NLP/StopWords/StopWords_Auditor.txt\"\n",
        "with open(stop_words_file_path, 'r') as f:\n",
        "    stop_words = set(f.read().splitlines())\n",
        "\n",
        "\n",
        "# Load positive and negative words\n",
        "positive_words = set()\n",
        "# negative_words = set()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLP/MasterDictionary/positive-words.txt\", 'r') as f:\n",
        "    positive_words.update(f.read().splitlines())\n",
        "\n",
        "# with open(\"/content/drive/MyDrive/NLP/MasterDictionary/negative-words.txt\", 'r') as f:\n",
        "#     negative_words.update(f.read().splitlines())\n",
        "# Load negative words from \"negative-words.txt\"\n",
        "negative_words_file_path = \"/content/drive/MyDrive/NLP/MasterDictionary/negative-words.txt\"\n",
        "try:\n",
        "    with open(negative_words_file_path, 'r', encoding='utf-8') as f:\n",
        "        negative_words = set(f.read().splitlines())\n",
        "except UnicodeDecodeError:\n",
        "    # If decoding as UTF-8 fails, try another encoding\n",
        "    with open(negative_words_file_path, 'r', encoding='latin-1') as f:\n",
        "        negative_words = set(f.read().splitlines())\n",
        "\n",
        "\n",
        "# Function to count syllables in a word\n",
        "def count_syllables(word):\n",
        "    vowels = \"aeiouy\"\n",
        "    count = 0\n",
        "    prev_char = ''\n",
        "\n",
        "    for char in word:\n",
        "        if char.lower() in vowels and prev_char not in vowels:\n",
        "            count += 1\n",
        "        prev_char = char.lower()\n",
        "\n",
        "    # Handling exceptions\n",
        "    if word.endswith(('es', 'ed')) and count > 1:\n",
        "        count -= 1\n",
        "\n",
        "    return max(1, count)\n",
        "\n",
        "# Function to calculate average word length\n",
        "def avg_word_length(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_chars = sum(len(word) for word in words)\n",
        "    total_words = len(words)\n",
        "    return total_chars / total_words if total_words != 0 else 0\n",
        "\n",
        "# Iterate over each file in the input folder\n",
        "for file_name in os.listdir(input_folder):\n",
        "    file_path = os.path.join(input_folder, file_name)\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "\n",
        "        # Tokenize sentences and words\n",
        "        sentences = sent_tokenize(text)\n",
        "        words = word_tokenize(text)\n",
        "\n",
        "        # Clean text\n",
        "        cleaned_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "        # Calculate variables\n",
        "        positive_score = sum(1 for word in cleaned_words if word in positive_words)\n",
        "        negative_score = sum(1 for word in cleaned_words if word in negative_words)\n",
        "        polarity_score = (positive_score - negative_score) / (positive_score + negative_score + 0.000001)\n",
        "        subjectivity_score = (positive_score + negative_score) / (len(cleaned_words) + 0.000001)\n",
        "        avg_sentence_length = len(words) / len(sentences) if len(sentences) != 0 else 0\n",
        "        percentage_complex = sum(1 for word in cleaned_words if count_syllables(word) > 2) / len(cleaned_words) if len(cleaned_words) != 0 else 0\n",
        "        fog_index = 0.4 * (avg_sentence_length + percentage_complex)\n",
        "        avg_words_sentence = len(words) / len(sentences) if len(sentences) != 0 else 0\n",
        "        complex_word_count = sum(1 for word in cleaned_words if count_syllables(word) > 2)\n",
        "        word_count = len(cleaned_words)\n",
        "        syllable_per_word = sum(count_syllables(word) for word in cleaned_words) / word_count if word_count != 0 else 0\n",
        "        personal_pronoun_count = len(re.findall(r'\\b(?:I|we|my|ours|us)\\b', text, flags=re.IGNORECASE))\n",
        "        avg_word_len = avg_word_length(text)\n",
        "\n",
        "        # Append values to lists\n",
        "        positive_scores.append(positive_score)\n",
        "        negative_scores.append(negative_score)\n",
        "        polarity_scores.append(polarity_score)\n",
        "        subjectivity_scores.append(subjectivity_score)\n",
        "        avg_sentence_lengths.append(avg_sentence_length)\n",
        "        percentage_complex_words.append(percentage_complex)\n",
        "        fog_indices.append(fog_index)\n",
        "        avg_words_per_sentence.append(avg_words_sentence)\n",
        "        complex_word_counts.append(complex_word_count)\n",
        "        word_counts.append(word_count)\n",
        "        syllable_per_words.append(syllable_per_word)\n",
        "        personal_pronouns.append(personal_pronoun_count)\n",
        "        avg_word_lengths.append(avg_word_len)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Skipping {file_name} - File not found.\")\n",
        "\n",
        "# Create DataFrame with calculated values\n",
        "output_data = pd.DataFrame({\n",
        "    'URL_ID': output_structure_df['URL_ID'],\n",
        "    'URL': output_structure_df['URL'],\n",
        "    'POSITIVE SCORE': positive_scores,\n",
        "    'NEGATIVE SCORE': negative_scores,\n",
        "    'POLARITY SCORE': polarity_scores,\n",
        "    'SUBJECTIVITY SCORE': subjectivity_scores,\n",
        "    'AVG SENTENCE LENGTH': avg_sentence_lengths,\n",
        "    'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
        "    'FOG INDEX': fog_indices,\n",
        "    'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,\n",
        "    'COMPLEX WORD COUNT': complex_word_counts,\n",
        "    'WORD COUNT': word_counts,\n",
        "    'SYLLABLE PER WORD': syllable_per_words,\n",
        "    'PERSONAL PRONOUNS': personal_pronouns,\n",
        "    'AVG WORD LENGTH': avg_word_lengths\n",
        "})\n",
        "\n",
        "# Save the output DataFrame to an Excel file\n",
        "output_data.to_excel(\"/content/drive/MyDrive/NLP/output_data.xlsx\", index=False)\n",
        "\n",
        "print(\"Data analysis and output file generation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGH11kN6Ssd6",
        "outputId": "99053ed2-f38a-4a47-a580-5ed6b2d88163"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data analysis and output file generation completed.\n"
          ]
        }
      ]
    }
  ]
}